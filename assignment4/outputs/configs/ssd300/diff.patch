On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   SSD/configs/change_lr.py
	modified:   SSD/ssd/modeling/backbones/basic.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	outputs/

no changes added to commit (use "git add" and/or "git commit -a")
e3c4a78f430412f6ee769d5b52e2d50f2a25efbd
diff --git a/assignment4/SSD/configs/change_lr.py b/assignment4/SSD/configs/change_lr.py
index 778d5f5..948230f 100644
--- a/assignment4/SSD/configs/change_lr.py
+++ b/assignment4/SSD/configs/change_lr.py
@@ -9,10 +9,11 @@ from .ssd300 import (
     backbone,
     data_train,
     data_val,
-    train_cpu_transform,
-    val_cpu_transform,
-    gpu_transform,
-    label_map
+    # train_cpu_transform,
+    # val_cpu_transform,
+    # gpu_transform,
+    label_map,
+    anchors
 )
 # We can keep all other configs the same, and only change the learning rate to a given value.
 # You can now start training with the following command: python train.py configs/change_lr.py
diff --git a/assignment4/SSD/ssd/modeling/backbones/basic.py b/assignment4/SSD/ssd/modeling/backbones/basic.py
index 430fc7e..8c0750f 100644
--- a/assignment4/SSD/ssd/modeling/backbones/basic.py
+++ b/assignment4/SSD/ssd/modeling/backbones/basic.py
@@ -1,6 +1,33 @@
 import torch
+from torch import nn
 from typing import Tuple, List
 
+def extractorLayer(in_channels, 
+                   out_channels, 
+                   num_filters, 
+                   output_stride=2, 
+                   output_padding=1):
+    extractor = nn.Sequential(
+            nn.ReLU(), 
+            nn.Conv2d(
+                in_channels=in_channels,
+                out_channels=num_filters,
+                kernel_size=3,
+                stride=1,
+                padding=1
+            ),
+            nn.ReLU(), 
+            nn.Conv2d(
+                in_channels=num_filters,
+                out_channels=out_channels,
+                kernel_size=3,
+                stride=output_stride,
+                padding=output_padding
+            ),
+            nn.ReLU(), 
+        )
+    return extractor
+
 
 class BasicModel(torch.nn.Module):
     """
@@ -21,6 +48,75 @@ class BasicModel(torch.nn.Module):
         self.out_channels = output_channels
         self.output_feature_shape = output_feature_sizes
 
+        self.conv_size = 3
+        self.conv_padding = 1
+        self.pool_stride = 2
+        self.pool_size = 2
+
+        self.first_extractor = nn.Sequential(
+            # Layer 1
+            nn.Conv2d(
+                in_channels=image_channels,
+                out_channels=32,
+                kernel_size=self.conv_size,
+                stride=1,
+                padding=self.conv_padding
+            ),
+            nn.ReLU(),
+            nn.MaxPool2d(kernel_size=self.pool_size, 
+                         stride=self.pool_stride
+            ),
+
+            # Layer 2
+            nn.Conv2d(
+                in_channels=32,
+                out_channels=64,
+                kernel_size=self.conv_size,
+                stride=1,
+                padding=self.conv_padding
+            ),
+            nn.ReLU(),
+            nn.MaxPool2d(kernel_size=self.pool_size, 
+                         stride=self.pool_stride
+            ),
+
+            # Layer 3
+            nn.Conv2d(
+                in_channels=64,
+                out_channels=64,
+                kernel_size=self.conv_size,
+                stride=1,
+                padding=self.conv_padding
+            ),
+            nn.ReLU(),
+
+            # Layer 4
+            nn.Conv2d(
+                in_channels=64,
+                out_channels=output_channels[0],
+                kernel_size=self.conv_size,
+                stride=2,
+                padding=self.conv_padding
+            ),
+            nn.ReLU(),
+        )
+
+        self.output2 = extractorLayer(output_channels[0], output_channels[1], 128)
+
+        self.output3 = extractorLayer(output_channels[1], output_channels[2], 256)
+
+        self.output4 = extractorLayer(output_channels[2], output_channels[3], 128)
+
+        self.output5 = extractorLayer(output_channels[3], output_channels[4], 128)
+
+        self.output6 = extractorLayer(output_channels[4], 
+                                output_channels[5], 
+                                128, 
+                                output_stride=1, 
+                                output_padding=0)
+        
+
+
     def forward(self, x):
         """
         The forward functiom should output features with shape:
@@ -35,6 +131,13 @@ class BasicModel(torch.nn.Module):
             shape(-1, output_channels[0], 38, 38),
         """
         out_features = []
+        out_features.append(self.first_extractor(x))
+        out_features.append(self.output2(out_features[0]))
+        out_features.append(self.output3(out_features[1]))
+        out_features.append(self.output4(out_features[2]))
+        out_features.append(self.output5(out_features[3]))
+        out_features.append(self.output6(out_features[4]))
+
         for idx, feature in enumerate(out_features):
             out_channel = self.out_channels[idx]
             h, w = self.output_feature_shape[idx]
@@ -43,5 +146,6 @@ class BasicModel(torch.nn.Module):
                 f"Expected shape: {expected_shape}, got: {feature.shape[1:]} at output IDX: {idx}"
         assert len(out_features) == len(self.output_feature_shape),\
             f"Expected that the length of the outputted features to be: {len(self.output_feature_shape)}, but it was: {len(out_features)}"
+        
         return tuple(out_features)
 
